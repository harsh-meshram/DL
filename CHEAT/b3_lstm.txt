# Install Kagglehub and dependencies (run once in Colab)
!pip install librosa tqdm kagglehub --quiet

import os
import numpy as np
import librosa
from tqdm import tqdm
import kagglehub
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, BatchNormalization, Dropout, Reshape, LSTM, Dense)
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split

# Download and extract GTZAN dataset
path = kagglehub.dataset_download("carlthome/gtzan-genre-collection")
data_dir = os.path.join(path, 'genres')
labels = sorted(os.listdir(data_dir))

# Function to extract mel-spectrogram features
def extract_melspectrogram(file_path, n_mels=128, max_pad_len=130):
    try:
        y, sr = librosa.load(file_path, duration=30)
        mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)
        mel_spec = librosa.power_to_db(mel_spec, ref=np.max)
        pad_width = max_pad_len - mel_spec.shape[1]
        if pad_width > 0:
            mel_spec = np.pad(mel_spec, pad_width=((0,0),(0,pad_width)), mode='constant')
        else:
            mel_spec = mel_spec[:, :max_pad_len]
        return mel_spec
    except Exception as e:
        print(f"Error processing {file_path}: {e}")
        return None

# Extract features and labels
X, y = [], []
print("Extracting Mel-spectrograms...")
for i, label in enumerate(labels):
    folder = os.path.join(data_dir, label)
    for f in tqdm(os.listdir(folder), desc=label):
        fp = os.path.join(folder, f)
        mel_spec = extract_melspectrogram(fp)
        if mel_spec is not None:
            X.append(mel_spec)
            y.append(i)

X = np.array(X)
y = np.array(y)
print("Feature and label shapes:", X.shape, y.shape)

# Add channel dimension for CNN input
X = X[..., np.newaxis]  # (samples, n_mels, time, channels)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

# Model architecture: CNN + LSTM
model = Sequential([
    Input(shape=(128, 130, 1)),

    Conv2D(32, (3, 3), activation='relu', padding='same'),
    MaxPooling2D((2, 2)),
    BatchNormalization(),
    Dropout(0.3),

    Conv2D(64, (3, 3), activation='relu', padding='same'),
    MaxPooling2D((2, 2)),
    BatchNormalization(),
    Dropout(0.3),

    # Reshape for LSTM: flatten spatial dims, keep channels as features
    Reshape((32 * 32, 64)),

    LSTM(128, return_sequences=False),
    Dropout(0.4),

    Dense(64, activation='relu'),
    Dropout(0.3),

    Dense(len(labels), activation='softmax')
])

# Compile the model
model.compile(
    loss='categorical_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)

model.summary()

# Train the model with early stopping
history = model.fit(
    X_train, y_train,
    epochs=50,
    batch_size=32,
    validation_data=(X_test, y_test),
    callbacks=[
        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
    ]
)

# Evaluate test accuracy
loss, accuracy = model.evaluate(X_test, y_test)
print(f"\nTest accuracy: {accuracy * 100:.2f}%")
